Topic title: Deep Dive into Deepseek: Training Process, RL techniques, MoE, ... <br>
Project title: Understanding DeepSeek: Architecture, Reasoning Capabilities and Training Processes <br>

Objectives <br>
This project aims to provide an overview of DeepSeek’s model family and training strategies. The focus is on reinforcement learning techniques, the Mixture-of-Experts (MoE) architecture and system-level optimizations used across models like DeepSeek-R1, V2, Coder-V2, V3 and Math \cite{tordjman2025comparative, kambhampati2025reasoning, sandmann2025benchmark, reuters2025, github2025}. \\
The first goal is to explain how DeepSeek fine-tunes its models. The analysis focuses on the training pipeline, especially how DeepSeek-R1 and R1-Zero apply reinforcement learning instead of traditional supervised learning \cite{guo2025deepseek, youtube2025}. \\
The second goal is to examine how DeepSeek combines reinforcement learning with chain-of-thought prompting. This helps to explain how reasoning becomes more accurate and logical in models like DeepSeek-Math \cite{shao2024deepseekmath}. \\
The third goal is to study the role of the Mixture-of-Experts architecture. The project will show how MoE, used in DeepSeek-V2, V2.5 and V3, helps reduce computational costs while maintaining strong performance \cite{liu2024deepseek, liu2024deepseekv3}. \\
The fourth goal is to investigate DeepSeek’s reward systems. The focus is on how these mechanisms improve output structure and logical reasoning, especially in DeepSeek-Math \cite{kambhampati2025reasoning, shao2024deepseekmath}. \\
The fifth goal is to explore the system-level improvements DeepSeek uses to optimize training and inference. This includes GPU optimizations such as kernel fusion and dynamic expert routing in large models like DeepSeek-V3 \cite{dreyer2025china, liu2024deepseekv3}. \\
The final goal is to compare DeepSeek models with other large language models like GPT-3.5 and LLaMA-2. This comparison will look at reasoning quality, efficiency and scalability \cite{tordjman2025comparative}.

Scope <br>
This project focuses on the technical design and training process of the DeepSeek language models. It examines the full range of DeepSeek models, including DeepSeek-R1 for general reasoning, DeepSeek-V2 and V3 for advanced language understanding, DeepSeek-Coder-V2 for programming tasks and DeepSeek-Math for mathematical problem solving. Each model offers unique design choices such as reinforcement learning, Mixture-of-Experts (MoE) and reward-based training strategies. This project does not examine ethical, commercial or social issues. It also does not include historical or business aspects of DeepSeek’s development. The focus remains on the technical and architectural innovations across the DeepSeek model family.

Strategy <br>
The project uses a research-based and analytical method to study DeepSeek's training strategies and model architectures. The focus is on official papers, GitHub repositories, technical blogs and recorded explainers \cite{github2025, youtube2025}. Key scientific sources include peer-reviewed studies on DeepSeek-R1, DeepSeek-V2, DeepSeek-V3, Coder-V2 and DeepSeek-Math. These models cover areas such as reasoning, efficiency, coding and mathematical problem solving \cite{tordjman2025comparative, kambhampati2025reasoning, wang2025jarvis}. \\
The project starts by outlining the development timeline of DeepSeek. This helps to understand changes from early models based on supervised fine-tuning to newer ones trained with reinforcement learning such as DeepSeek-R1-Zero. The next step focuses on how chain-of-thought prompting is used to improve reasoning in advanced models like DeepSeek-R1 and DeepSeek-V3. To understand the Mixture-of-Experts (MoE) approach used in DeepSeek-V2, V2.5, and V3, the project reviews model blueprints and routing logic. This helps explain how only task-relevant parts of the model are activated which reduces computing cost while maintaining quality \cite{conroy2025deepseek, reuters2025}. Reinforcement learning techniques are examined with a focus on Group Relative Policy Optimization (GRPO), as used in DeepSeek-Math. The project looks at how this reward system improves reasoning structure and output formatting. Reward definitions and training procedures are analyzed to support this part \cite{kambhampati2025reasoning}. The project also examines GPU and system-level optimizations used in DeepSeek’s development. These include memory-efficient attention and dynamic expert routing which improve training and inference speed \cite{dreyer2025china}. Benchmark results and task-specific examples from models like GPT-3.5 and LLaMA-2 are used for comparison. This provides a clear view of DeepSeek’s strengths in reasoning, efficiency, and scalability \cite{tordjman2025comparative, sandmann2025benchmark}.

Anticipated Outcomes <br>
This project will give an overview of DeepSeek’s training methods and model structure. It will show how the model moves from pretraining to fine-tuning using reinforcement learning and chain-of-thought prompting. It will explain how models like DeepSeek-R1 use reinforcement learning to replace standard supervised fine-tuning. It will also show how DeepSeek-Math improves step-by-step reasoning using reward signals. The project will describe how Mixture-of-Experts architectures, used in DeepSeek-V2, V2.5 and V3, reduce computational costs by activating only the needed expert modules. It will examine GPU and system-level optimizations that improve speed and reduce resource use. The project will compare DeepSeek models with baseline models such as GPT-3.5 and LLaMA-2 by looking at reasoning ability, efficiency and scalability. The project will offer a helpful reference for researchers who want to understand or build similar systems. It will also help others understand how to build models that are both powerful and cost-effective \cite{reuters2025, github2025}.

Submission Format <br>
The final submission will be a written report in digital format. The report will follow a clear and structured layout. It will include an introduction, background information, research questions, methods, results, discussion and conclusion. Each section will focus on one main idea to help the reader follow the analysis easily. The report will also contain visual elements to support the explanations. These visual elements will make complex ideas easier to understand. \\
This format is suitable because it presents information in a logical way. It allows for deep analysis while keeping the structure simple and clear. A written report is easy to share and read on different devices. It also supports the use of references which are important for academic work. The digital format makes it easy to include links to external sources such as research papers, videos and GitHub pages \cite{youtube2025, github2025}. This helps the reader explore the topic further if they want more details.
